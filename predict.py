import streamlit as st      # import å®Œäº†ä¹‹åŽç›´æŽ¥å¡«ç½‘é¡µå†…å®¹
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from PIL import Image

txt_BP = '''# æ€§åˆ«åˆ†ç±»ä»»åŠ¡å®žçŽ°
import cv2, os
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from sklearn.metrics import accuracy_score

# 1.æ ¹æ®æ•°æ®æž„å»ºåˆ†ç±»æ¨¡åž‹ï¼Œä½¿ç”¨trainingæ•°æ®é›†è¿›è¡Œæ¨¡åž‹è®­ç»ƒï¼Œå¹¶è°ƒç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹ç»™å‡ºéªŒè¯é›†çš„æ­£ç¡®çŽ‡
# 2.è°ƒç”¨æ‘„åƒå¤´è¿›è¡Œæ‹ç…§ï¼Œè¯†åˆ«ç…§ç‰‡äººç‰©çš„æ€§åˆ«
# cap = cv2.VideoCapture(0)   # 0è¡¨ç¤ºé»˜è®¤æ‘„åƒå¤´
# _, img = cap.read()         # cap.read()ä¼šè¿”å›žä¸¤ä¸ªå€¼(1.å¸ƒå°”å€¼ï¼Œtrue=å·²æˆåŠŸæ‹ç…§ï¼Œ2.å›¾ç‰‡çš„äºŒç»´å±•å¼€)
# # çœ‹çœ‹è‡ªå·±é•¿ä»€ä¹ˆæ ·
# # plt.imshow(img[:, :, ::-1])     # è®°å¾— matplotlibå’Œ cv2 çš„æ ¼å¼æ˜¯ç›¸åçš„ï¼Œæ‰€ä»¥è¦::-1ï¼ˆ RBGå’Œ BRGï¼‰
# # plt.show()
# haar = cv2.CascadeClassifier("D:/Python38/Lib/site-packages/cv2/data/haarcascade_frontalface_alt.xml")      # è¿™ä¸ªæ˜¯äººè„¸è¯†åˆ«çš„æ–‡ä»¶
# faces = haar.detectMultiScale(img)     # è¿™ä¸€æ­¥æ˜¯äººè„¸æ£€æµ‹
# for x, y, w, h in faces:               # å·¦ä¸Šè§’ç‚¹çš„ x,yï¼Œä»¥åŠå¯¹åº”çš„å®½åº¦ã€é«˜åº¦
#     print(x, y, w, h)
#     your_face = img[y:y+w, x:x+h, :]        # åœ¨æ•´ä¸ªç…§ç‰‡ä¸­æˆªå–ä½ çš„è„¸
#     plt.imshow(your_face[:, :, ::-1])       # ä¸æƒ³å˜æˆè“ç²¾çµè®°å¾—åè½¬ BRG
#     plt.show()
# cap.release()                          # å…³æŽ‰æ‘„åƒå¤´

# æ‰¹é‡è¯»å–å›¾ç‰‡
def get_info(train_test_name, male_female_name):
    count = 0
    path = './' + str(train_test_name) + '/' + str(male_female_name)
    face_record = []
    face_name = os.listdir(path)
    for i in face_name:
        count += 1
        if count % 1000 == 0:
            print(f'å·²å¤„ç†åˆ°ç¬¬{count}å¼ å›¾ç‰‡...')
        os_path = path + '/' + i
        img = cv2.imread(os_path)
        img = cv2.resize(img, (64, 64))  # ç»Ÿä¸€å›¾ç‰‡å¤§å°
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # å¯¹ img_2 è¿›è¡Œ ä»Ž BGRçš„å½©è‰²å›¾ç‰‡è½¬è‡³ç°åº¦å›¾ ï¼ˆ BGR2GRAYï¼‰
        face_record.append(img)
    y = np.zeros((len(face_record), )) if male_female_name == 'female' else np.ones((len(face_record), ))
    x = face_record
    return x, y

x_female_train, y_female_train = get_info('Training', 'female')
x_male_train, y_male_train = get_info('Training', 'male')
x_female_test, y_female_test = get_info('Validation', 'female')
x_male_test, y_male_test = get_info('Validation', 'male')

# åˆå¹¶è®­ç»ƒã€æµ‹è¯•é›†
x_train, y_train = np.array(x_male_train + x_female_train), np.r_[y_male_train, y_female_train]
x_test, y_test = np.array(x_male_test + x_female_test), np.r_[y_male_test, y_female_test]
# æ•°æ®å¤„ç†æ ‡å‡†åŒ–ï¼
x_train_input, x_test_input = tf.constant((x_train/ 255), dtype=tf.float32), tf.constant((x_test/ 255), dtype=tf.float32)

# è®¾å‚ï¼
input_size, hidden_size1, out_size =\
    x_train.shape[0], 2 ** 8, 1 if len(set(y_train)) == 2 else len(set(y_train))
# æ¨¡åž‹å¼€å§‹æžèµ·æ¥
tf.keras.backend.clear_session()
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten(input_shape=(64, 64)))
model.add(tf.keras.layers.Dense(units=hidden_size1, activation=tf.keras.activations.sigmoid))
model.add(tf.keras.layers.Dense(units=out_size, activation=tf.keras.activations.sigmoid))

model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, decay=1e-6, momentum=0.9),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=tf.keras.metrics.BinaryAccuracy())
model.summary()
hist = model.fit(x_train_input, y_train, epochs=45, batch_size=500, validation_data=(x_test_input, y_test))

# å¯¹è®­ç»ƒé›†ä¹ŸåšåŒæ ·çš„æ“ä½œ
y_test_predict = model.predict(x_test_input)
y_test_out = y_test_predict >= 0.5
print(f'æ­£ç¡®çŽ‡ï¼š{accuracy_score(y_test, y_test_out)}')

# å…ˆå¤„ç†
# test = cv2.resize(your_face, (64, 64))
# test = cv2.cvtColor(test, cv2.COLOR_BGR2GRAY)
# test = test.reshape(-1, 64, 64)
# test = tf.constant((test/ 255), dtype=tf.float32)
# out = model.predict(test)
# out = out >= 0.5
# sex = 'å¥³' if out == 0 else 'ç”·'
# print(f'è¿™æ˜¯{sex}æ€§')'''
txt_CNN = '''# æ€§åˆ«åˆ†ç±»ä»»åŠ¡å®žçŽ°
import cv2, os
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from sklearn.metrics import accuracy_score

# 1.æ ¹æ®æ•°æ®æž„å»ºåˆ†ç±»æ¨¡åž‹ï¼Œä½¿ç”¨trainingæ•°æ®é›†è¿›è¡Œæ¨¡åž‹è®­ç»ƒï¼Œå¹¶è°ƒç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹ç»™å‡ºéªŒè¯é›†çš„æ­£ç¡®çŽ‡
# 2.è°ƒç”¨æ‘„åƒå¤´è¿›è¡Œæ‹ç…§ï¼Œè¯†åˆ«ç…§ç‰‡äººç‰©çš„æ€§åˆ«
# cap = cv2.VideoCapture(0)   # 0è¡¨ç¤ºé»˜è®¤æ‘„åƒå¤´
# _, img = cap.read()         # cap.read()ä¼šè¿”å›žä¸¤ä¸ªå€¼(1.å¸ƒå°”å€¼ï¼Œtrue=å·²æˆåŠŸæ‹ç…§ï¼Œ2.å›¾ç‰‡çš„äºŒç»´å±•å¼€)
# # çœ‹çœ‹è‡ªå·±é•¿ä»€ä¹ˆæ ·
# # plt.imshow(img[:, :, ::-1])     # è®°å¾— matplotlibå’Œ cv2 çš„æ ¼å¼æ˜¯ç›¸åçš„ï¼Œæ‰€ä»¥è¦::-1ï¼ˆ RBGå’Œ BRGï¼‰
# # plt.show()
# haar = cv2.CascadeClassifier("D:/Python38/Lib/site-packages/cv2/data/haarcascade_frontalface_alt.xml")      # è¿™ä¸ªæ˜¯äººè„¸è¯†åˆ«çš„æ–‡ä»¶
# faces = haar.detectMultiScale(img)     # è¿™ä¸€æ­¥æ˜¯äººè„¸æ£€æµ‹
# for x, y, w, h in faces:               # å·¦ä¸Šè§’ç‚¹çš„ x,yï¼Œä»¥åŠå¯¹åº”çš„å®½åº¦ã€é«˜åº¦
#     print(x, y, w, h)
#     your_face = img[y:y+w, x:x+h, :]        # åœ¨æ•´ä¸ªç…§ç‰‡ä¸­æˆªå–ä½ çš„è„¸
#     plt.imshow(your_face[:, :, ::-1])       # ä¸æƒ³å˜æˆè“ç²¾çµè®°å¾—åè½¬ BRG
#     plt.show()
# cap.release()                          # å…³æŽ‰æ‘„åƒå¤´

# æ‰¹é‡è¯»å–å›¾ç‰‡
def get_info(train_test_name, male_female_name):
    count = 0
    path = './' + str(train_test_name) + '/' + str(male_female_name)
    face_record = []
    face_name = os.listdir(path)
    for i in face_name:
        count += 1
        if count % 1000 == 0:
            print(f'å·²å¤„ç†åˆ°ç¬¬{count}å¼ å›¾ç‰‡...')
        os_path = path + '/' + i
        img = cv2.imread(os_path)
        img = cv2.resize(img, (64, 64))  # ç»Ÿä¸€å›¾ç‰‡å¤§å°
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # å¯¹ img_2 è¿›è¡Œ ä»Ž BGRçš„å½©è‰²å›¾ç‰‡è½¬è‡³ç°åº¦å›¾ ï¼ˆ BGR2GRAYï¼‰
        face_record.append(img)
    y = np.zeros((len(face_record), )) if male_female_name == 'female' else np.ones((len(face_record), ))
    x = face_record
    return x, y

x_female_train, y_female_train = get_info('Training', 'female')
x_male_train, y_male_train = get_info('Training', 'male')
x_female_test, y_female_test = get_info('Validation', 'female')
x_male_test, y_male_test = get_info('Validation', 'male')

# åˆå¹¶è®­ç»ƒã€æµ‹è¯•é›†
x_train, y_train = np.array(x_male_train + x_female_train), np.r_[y_male_train, y_female_train]
x_test, y_test = np.array(x_male_test + x_female_test), np.r_[y_male_test, y_female_test]
# æ•°æ®å¤„ç†æ ‡å‡†åŒ–ï¼
x_train_input, x_test_input = tf.constant((x_train/ 255), dtype=tf.float32), tf.constant((x_test/ 255), dtype=tf.float32)

# è®¾å‚ï¼
input_size, hidden_size, out_size =\
    x_train.shape[0], 2 ** 5, 1 if len(set(y_train)) == 2 else len(set(y_train))
# æ¨¡åž‹å¼€å§‹æžèµ·æ¥
tf.keras.backend.clear_session()
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(4, 4), input_shape=(64, 64, 1), activation='relu'))
model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(4, 4), activation='relu'))
model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(units=hidden_size, activation='relu'))
model.add(tf.keras.layers.Dense(units=out_size, activation=tf.keras.activations.sigmoid))

model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=tf.keras.metrics.BinaryAccuracy())
model.summary()
hist = model.fit(x_train_input, y_train, epochs=50, batch_size=200, validation_split=0.2)
model.evaluate(x_test_input, y_test)        # æŸ¥çœ‹ modelåœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®åº¦

loss_record, accuracy = hist.history['loss'], hist.history['binary_accuracy']
plt.subplot(1, 2, 1); plt.title('loss'); plt.plot(loss_record, 'r')
plt.subplot(1, 2, 2); plt.title('accuracy'); plt.plot(accuracy, 'b')
plt.show()
# å¯¹è®­ç»ƒé›†ä¹ŸåšåŒæ ·çš„æ“ä½œ
y_test_predict = model.predict(x_test_input)
y_test_out = y_test_predict >= 0.5
print(f'æ­£ç¡®çŽ‡ï¼š{accuracy_score(y_test, y_test_out)}')
'''


st.set_page_config(page_title='ç”·å¥³è¯†åˆ«', page_icon='ðŸ’¥')
st.title('ç”·å¥³è¯†åˆ«'.center(40, '-'))
st.subheader('æœ¬ç½‘é¡µé¢„æµ‹ç»“æžœ99%æ­£ç¡®ï¼')

@st.cache
def img_process(image):
    image = np.array(Image.open(image), dtype=np.uint8)     # è¦æŠŠç…§ç‰‡è½¬æ¢æˆ numpyå¤šç»´æ•°ç»„
    haar = cv2.CascadeClassifier("D:/Python38/Lib/site-packages/cv2/data/haarcascade_frontalface_alt.xml")  # è¿™ä¸ªæ˜¯äººè„¸è¯†åˆ«çš„æ–‡ä»¶
    faces = haar.detectMultiScale(image)  # è¿™ä¸€æ­¥æ˜¯äººè„¸æ£€æµ‹
    x, y, w, h = faces[0, :]  # å·¦ä¸Šè§’ç‚¹çš„ x,yï¼Œä»¥åŠå¯¹åº”çš„å®½åº¦ã€é«˜åº¦
    your_face = image[y:y + w, x:x + h, :]  # åœ¨æ•´ä¸ªç…§ç‰‡ä¸­æˆªå–ä½ çš„è„¸
    test = cv2.resize(your_face, (64, 64))
    test = cv2.cvtColor(test, cv2.COLOR_BGR2GRAY)
    test = test.reshape(-1, 64, 64, 1)
    test = tf.constant((test / 255), dtype=tf.float32)
    out = model.predict(test)
    out = out >= 0.5
    sex = 'å¥³' if out == 0 else 'ç”·'
    return sex

img = st.file_uploader('è¯·åœ¨æ­¤å¤„è¾“å…¥æ‚¨çš„ç…§ç‰‡')

try:
    st.image(img)
except:
    st.text('')

model_select = st.radio('è¯·é€‰æ‹©ä½ è¦ç”¨çš„æ¨¡åž‹ï¼š', ['BP', 'CNN'])

if model_select == 'BP':
    model = tf.keras.models.load_model('./bp-faces-256.h5')
    st.text('ä½ é€‰æ‹©äº†BPæ¨¡åž‹')
    with st.expander('ç‚¹å‡»æŸ¥çœ‹æ¨¡åž‹ä»£ç ï¼š'):
        st.code(txt_BP, language='python')
    if st.button('ç‚¹å‡»æ£€æµ‹ï¼š'):
        try:
            sex = img_process(img)
            st.subheader(f'>>>>>é¢„æµ‹ç»“æžœä¸º{sex}æ€§')
        except:
            st.subheader('æœªæ£€æµ‹å‡ºäººè„¸')

elif model_select == 'CNN':
    model = tf.keras.models.load_model('./CNN - faces.h5')
    st.text('ä½ é€‰æ‹©äº†CNNæ¨¡åž‹')
    with st.expander('ç‚¹å‡»æŸ¥çœ‹æ¨¡åž‹ä»£ç ï¼š'):
        st.code(txt_CNN, language='python')
    if st.button('ç‚¹å‡»æ£€æµ‹ï¼š'):
        try:
            sex = img_process(img)
            st.subheader(f'>>>>>é¢„æµ‹ç»“æžœä¸º{sex}æ€§')
        except:
            st.subheader('æœªæ£€æµ‹å‡ºäººè„¸')

